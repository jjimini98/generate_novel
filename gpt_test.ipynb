{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## gpt 테스트 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "pathList = [\"C:/Users/Jimin/PycharmProjects/graduation\",\"C:/Users/Jimin/PycharmProjects/graduation/data\"] \n",
    "for p in pathList : \n",
    "    sys.path.append(p)\n",
    "from connect_mongo import connect_mongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
      "The class this function is called from is 'PreTrainedTokenizerFast'.\n"
     ]
    }
   ],
   "source": [
    "#토크나이저 로드\n",
    "from transformers import PreTrainedTokenizerFast, GPT2LMHeadModel\n",
    "\n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained(\"skt/kogpt2-base-v2\",bos_token='</s>', eos_token='</s>', unk_token='<unk>', pad_token='<pad>', mask_token='<mask>')\n",
    "\n",
    "#모델로드\n",
    "model = GPT2LMHeadModel.from_pretrained('skt/kogpt2-base-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mongo db에서 contents를 가져온다\n",
    "def get_contents():\n",
    "    novelDB = connect_mongo()\n",
    "    contents = novelDB['contents']\n",
    "    all_data = contents.find()\n",
    "    # training_corpus_list=list()\n",
    "    for x in all_data:\n",
    "        training_corpus = dict() \n",
    "        training_corpus['title'] = x.get('title') \n",
    "        training_corpus['contents']  \n",
    "        content = x.get('contents')\n",
    "        if len(content) != 1:\n",
    "            contents.extend(content)\n",
    "    return contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contents = get_contents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train,test =train_test_split(contents,test_size=0.15)\n",
    "\n",
    "with open('test.txt','w',encoding='utf-8') as f :\n",
    "    data = ''\n",
    "    for i in test:\n",
    "        text = i.strip()\n",
    "        data += text + ' '\n",
    "    f.write(data)\n",
    "    \n",
    "with open('train.txt','w',encoding='utf-8') as f :\n",
    "    data = ''\n",
    "    for i in train:\n",
    "        text = i.strip()\n",
    "        data += text + ' '\n",
    "    f.write(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TextDataset,DataCollatorForLanguageModeling\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TextDataset(tokenizer=tokenizer,file_path='test.txt',block_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = TextDataset(tokenizer=tokenizer,file_path='train.txt',block_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TextDataset(tokenizer=tokenizer,file_path='test.txt',block_size=128)\n",
    "# test_dataset = TextDataset(tokenizer=tokenizer,file_path='train.txt',block_size=128)\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments, AutoModelWithLMHead\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./gpt_models/kogpt2-proto\", #The output directory\n",
    "    overwrite_output_dir=True, #overwrite the content of the output directory\n",
    "    num_train_epochs=3, # number of training epochs\n",
    "    per_device_train_batch_size=16, # batch size for training\n",
    "     per_device_eval_batch_size=16,  # batch size for evaluation\n",
    "     eval_steps = 400, # Number of update steps between two evaluations.\n",
    "     save_steps=800, # after # steps model is saved\n",
    "     warmup_steps=500,# number of warmup steps for learning rate scheduler\n",
    "     )\n",
    "trainer = Trainer(\n",
    "     model=model,\n",
    "     args=training_args,\n",
    "     data_collator=data_collator,\n",
    "     train_dataset=train_dataset,\n",
    "    #  eval_dataset=test_dataset,\n",
    "    #  prediction_loss_only=True,\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline,AutoConfig\n",
    "# config = AutoConfig.from_pretrained('gpt_models/kogpt2-proto/config.json')\n",
    "# print(config)\n",
    "# config['max_length'] = 800\n",
    "chef = pipeline('text-generation',model='C:/Users/Jimin/PycharmProjects/graduation/gpt_models/kogpt2-contents/checkpoint-140000', tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'generated_text': '철수와 영희. 다시는 돌아오지 않는 날이 있다면.   윤 씨는 며칠 전보다 더 부은 듯 보였다. 물이 새고 바람이 새고 그럴 때마다 손이 새는 것 같았다. 하지만 꼭 좋은 일만은 아닌 것 같았다. 아무리 노력해도'}],\n",
       " [{'generated_text': '철수와 영희. 하나같이 손이 없다는 사실. 어머니는 봄에만 해도 어깨에 팔을 붙이고 밥 짓는 것을 좋아했었다. 할머니가 집에 들어오면 해먹자고 할 때부터. 레사는 두 알을 엄마와 나에게 내밀었다. 레사가 팔꿈치를 대고 날'}],\n",
       " [{'generated_text': '철수와 영희. 둘 다 벽돌 공장 근처인데 둘 다 롤러코스터가 띄엄띄엄 서 있는 게 똑같았다. 나도 처음에는 임대업자 자격이 없다고 생각했다. 하지만 청년 박순종은 수리 의지와는 상관없이 저렴한 가격의 철수를 찾는다. 그것은 뼈'}],\n",
       " [{'generated_text': '철수와 영희.하염없이 두 발로 마마를 차기 앞에 앉아 마마의 모습을 생경하게 훑어보았다. 나는 무언가 할 말이 있다는 듯 입술을 달싹였다. 초인종이 울렸다. 무슨 말을 하건 안 돼'}],\n",
       " [{'generated_text': '철수와 영희. 윤은 하염없이 걸었다. 언덕 아래 건물들이 겹겹이 쌓인 담장들과 다리를 건너 섬을 오가는 강둑들이 보였다. 낯선 풍경이 이어지더니 익숙해졌다. 그녀는 익숙하다는 듯 이곳까지 들고 걸어갔'}]]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chef(['철수와 영희','철수와 영희','철수와 영희','철수와 영희','철수와 영희'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_list = ['철수와 영희','철수와 영희','철수와 영희','철수와 영희','철수와 영희']\n",
    "for i in temp_list:\n",
    "    chef(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0820 GPT Model test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpt_model import gpt_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model = gpt_model()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f9f85f796d01129d0dd105a088854619f454435301f6ffec2fea96ecbd9be4ac"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
